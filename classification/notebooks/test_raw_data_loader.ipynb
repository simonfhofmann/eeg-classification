{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10294bf1",
   "metadata": {},
   "source": [
    "### Test raw loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c22dd82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIG CHECK\n",
      "============================================================\n",
      "\n",
      "MARKERS:\n",
      "  BASELINE_START: 1\n",
      "  STIMULUS_START: 2\n",
      "  STIMULUS_END: 5\n",
      "  STIMULUS_END_ALT: 6\n",
      "  BREAK: 3\n",
      "  EXPERIMENT_RESUME: 14\n",
      "  EXPERIMENT_END: 15\n",
      "\n",
      "PARTICIPANT_INFO:\n",
      "  Sub01 (yannick): no crashes\n",
      "  Sub02 (daniel): no crashes\n",
      "  Sub03 (simon): crashes: [32]\n",
      "  Sub04 (karsten): no crashes\n",
      "  Sub05 (philipp): no crashes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "for mod in list(sys.modules.keys()):\n",
    "    if 'config' in mod or 'raw_loader' in mod or 'data.loaders' in mod:\n",
    "        del sys.modules[mod]\n",
    "from config import MARKERS, PARTICIPANT_INFO, DATA_DIR\n",
    "from data.loaders.raw_loader import RawEEGLoader\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIG CHECK\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nMARKERS:\")\n",
    "for k, v in MARKERS.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(\"\\nPARTICIPANT_INFO:\")\n",
    "for sub_id, info in PARTICIPANT_INFO.items():\n",
    "    crashes = info.get('crashes', [])\n",
    "    crash_str = f\"crashes: {[c['repeated_eeg_trial'] for c in crashes]}\" if crashes else \"no crashes\"\n",
    "    print(f\"  {sub_id} ({info['name']}): {crash_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49656d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST: Loading Sub03 (Simon) with crash handling\n",
      "============================================================\n",
      "\n",
      "Loader config:\n",
      "  event_id: {'stimulus': 2}\n",
      "  epoch_tmin: -3.0\n",
      "  epoch_tmax: 32.0\n",
      "  baseline: (-3.0, -0.1)\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Excluded 1 trials: [32]\n",
      "\n",
      "Loaded data:\n",
      "  Shape: (77, 30, 17501)\n",
      "  n_trials: 77\n",
      "  n_channels: 30\n",
      "  n_timepoints: 17501\n",
      "  sfreq: 500 Hz\n",
      "  Excluded trials: [32]\n"
     ]
    }
   ],
   "source": [
    "# Test loading Sub03 (Simon) - should auto-exclude trial 32\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TEST: Loading Sub03 (Simon) with crash handling\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "loader = RawEEGLoader()\n",
    "print(f\"\\nLoader config:\")\n",
    "print(f\"  event_id: {loader.config['event_id']}\")\n",
    "print(f\"  epoch_tmin: {loader.config['epoch_tmin']}\")\n",
    "print(f\"  epoch_tmax: {loader.config['epoch_tmax']}\")\n",
    "print(f\"  baseline: {loader.config['baseline']}\")\n",
    "\n",
    "data = loader.load(\n",
    "    eeg_path=DATA_DIR / \"Sub03\" / \"Simon.vhdr\",\n",
    "    participant_id=\"Sub03\"\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded data:\")\n",
    "print(f\"  Shape: {data.X.shape}\")\n",
    "print(f\"  n_trials: {data.X.shape[0]}\")\n",
    "print(f\"  n_channels: {data.X.shape[1]}\")\n",
    "print(f\"  n_timepoints: {data.X.shape[2]}\")\n",
    "print(f\"  sfreq: {data.sfreq} Hz\")\n",
    "print(f\"  Excluded trials: {data.metadata['excluded_trials']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iz2xziqxs6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA QUALITY CHECK (Percentile-based)\n",
      "============================================================\n",
      "\n",
      "Amplitude distribution (µV):\n",
      "    0th percentile:  -7740.3 µV ← extreme\n",
      "    1th percentile:   -254.5 µVartifacts present\n",
      "    5th percentile:    -71.3 µV\n",
      "   25th percentile:    -21.9 µV\n",
      "   50th percentile:     -1.9 µV\n",
      "   75th percentile:     18.0 µV\n",
      "   95th percentile:     59.5 µV\n",
      "   99th percentile:    116.6 µV\n",
      "  100th percentile:   3772.5 µV ← extreme\n",
      "\n",
      "% of data within ±150 µV: 97.8%\n",
      "\n",
      "Trials with max amplitude < 150 µV: 19 / 77\n",
      "\n",
      "Trials exceeding threshold (0-indexed): 58 trials\n",
      "\n",
      "Baseline check (should be ~0 after correction):\n",
      "  Mean of baseline means: -0.26 µV\n",
      "  Std of baseline means: 2.15 µV\n",
      "  ✓ Baseline correction appears to be working\n"
     ]
    }
   ],
   "source": [
    "# Better quality check using percentiles\n",
    "import numpy as np\n",
    "\n",
    "X = data.X\n",
    "\n",
    "print(\"DATA QUALITY CHECK (Percentile-based)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Convert to µV for readability\n",
    "X_uv = X * 1e6\n",
    "\n",
    "print(f\"\\nAmplitude distribution (µV):\")\n",
    "percentiles = [0, 1, 5, 25, 50, 75, 95, 99, 100]\n",
    "values = np.percentile(X_uv, percentiles)\n",
    "for p, v in zip(percentiles, values):\n",
    "    marker = \"\"\n",
    "    if p == 0 or p == 100:\n",
    "        marker = \" ← extreme\"\n",
    "    elif p == 1 or p == 99:\n",
    "        if abs(v) > 150:\n",
    "            marker = \" artifacts present\"\n",
    "    print(f\"  {p:3d}th percentile: {v:8.1f} µV{marker}\")\n",
    "\n",
    "# Check what % of data is within normal range\n",
    "normal_range = 150  # µV\n",
    "within_range = np.mean(np.abs(X_uv) < normal_range) * 100\n",
    "print(f\"\\n% of data within ±{normal_range} µV: {within_range:.1f}%\")\n",
    "\n",
    "# Per-trial quality\n",
    "trial_max = np.abs(X_uv).max(axis=(1, 2))\n",
    "good_trials = np.sum(trial_max < normal_range)\n",
    "print(f\"\\nTrials with max amplitude < {normal_range} µV: {good_trials} / {len(X)}\")\n",
    "\n",
    "# Identify bad trials\n",
    "bad_trial_idx = np.where(trial_max >= normal_range)[0]\n",
    "print(f\"\\nTrials exceeding threshold (0-indexed): {len(bad_trial_idx)} trials\")\n",
    "if len(bad_trial_idx) <= 20:\n",
    "    print(f\"  Indices: {list(bad_trial_idx)}\")\n",
    "    print(f\"  Max amplitudes (µV): {[f'{trial_max[i]:.0f}' for i in bad_trial_idx]}\")\n",
    "\n",
    "# Check baseline correction\n",
    "baseline_end = int(3 * data.sfreq)  # First 3 seconds = baseline\n",
    "baseline_means = X_uv[:, :, :baseline_end].mean(axis=(1, 2))\n",
    "print(f\"\\nBaseline check (should be ~0 after correction):\")\n",
    "print(f\"  Mean of baseline means: {baseline_means.mean():.2f} µV\")\n",
    "print(f\"  Std of baseline means: {baseline_means.std():.2f} µV\")\n",
    "print(f\"  Baseline correction appears to be working\" if abs(baseline_means.mean()) < 5 else \" Baseline may not be corrected properly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fwzf6af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to:\n",
      "c:\\Users\\yanni\\Desktop\\TUM MSEI\\2. Semester\\Lab\\Recording\\classification\\notebooks\\epoch_visualization.png\n",
      "\n",
      "Open the PNG file to view the plots.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get data\n",
    "X = data.X * 1e6  # Convert to µV\n",
    "times = np.linspace(-3, 32, X.shape[2])\n",
    "ch_names = data.ch_names\n",
    "\n",
    "# Find a good trial and a bad trial for comparison\n",
    "trial_max = np.abs(X).max(axis=(1, 2))\n",
    "good_trial = np.argmin(trial_max)\n",
    "bad_trial = np.argmax(trial_max)\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Good trial - all channels (butterfly plot)\n",
    "ax = axes[0, 0]\n",
    "for ch in range(X.shape[1]):\n",
    "    ax.plot(times, X[good_trial, ch, :], alpha=0.5, linewidth=0.5)\n",
    "ax.axvline(0, color='r', linestyle='--', label='Stimulus onset')\n",
    "ax.axvspan(-3, 0, alpha=0.1, color='green', label='Baseline')\n",
    "ax.set_xlim(-3, 32)\n",
    "ax.set_ylim(-150, 150)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Amplitude (µV)')\n",
    "ax.set_title(f'Good Trial #{good_trial+1} (max: {trial_max[good_trial]:.0f} µV)')\n",
    "\n",
    "# 2. Bad trial - all channels\n",
    "ax = axes[0, 1]\n",
    "for ch in range(X.shape[1]):\n",
    "    ax.plot(times, X[bad_trial, ch, :], alpha=0.5, linewidth=0.5)\n",
    "ax.axvline(0, color='r', linestyle='--')\n",
    "ax.axvspan(-3, 0, alpha=0.1, color='green')\n",
    "ax.set_xlim(-3, 32)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Amplitude (µV)')\n",
    "ax.set_title(f'Bad Trial #{bad_trial+1} (max: {trial_max[bad_trial]:.0f} µV)')\n",
    "\n",
    "# 3. Average across all trials - single channel (Cz)\n",
    "ax = axes[1, 0]\n",
    "ch_idx = ch_names.index('Cz') if 'Cz' in ch_names else 0\n",
    "mean_signal = X[:, ch_idx, :].mean(axis=0)\n",
    "std_signal = X[:, ch_idx, :].std(axis=0)\n",
    "ax.plot(times, mean_signal, 'b', linewidth=1)\n",
    "ax.fill_between(times, mean_signal - std_signal, mean_signal + std_signal, alpha=0.3)\n",
    "ax.axvline(0, color='r', linestyle='--')\n",
    "ax.axvspan(-3, 0, alpha=0.1, color='green')\n",
    "ax.set_xlim(-3, 32)\n",
    "ax.set_ylim(-100, 100)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Amplitude (µV)')\n",
    "ax.set_title(f'Average ± STD - Channel {ch_names[ch_idx]}')\n",
    "\n",
    "# 4. Multiple random trials - single channel\n",
    "ax = axes[1, 1]\n",
    "np.random.seed(42)\n",
    "random_trials = np.random.choice(len(X), size=min(10, len(X)), replace=False)\n",
    "for t in random_trials:\n",
    "    ax.plot(times, X[t, ch_idx, :], alpha=0.5, linewidth=0.5, label=f'Trial {t+1}')\n",
    "ax.axvline(0, color='r', linestyle='--')\n",
    "ax.axvspan(-3, 0, alpha=0.1, color='green')\n",
    "ax.set_xlim(-3, 32)\n",
    "ax.set_ylim(-150, 150)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Amplitude (µV)')\n",
    "ax.set_title(f'10 Random Trials - Channel {ch_names[ch_idx]}')\n",
    "\n",
    "# 5. Trial variance over time\n",
    "ax = axes[2, 0]\n",
    "variance_over_time = X.var(axis=(0, 1))\n",
    "ax.plot(times, variance_over_time, 'purple', linewidth=1)\n",
    "ax.axvline(0, color='r', linestyle='--')\n",
    "ax.axvspan(-3, 0, alpha=0.1, color='green')\n",
    "ax.set_xlim(-3, 32)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Variance (µV²)')\n",
    "ax.set_title('Variance Over Time (spikes = artifacts)')\n",
    "\n",
    "# 6. Per-channel variability\n",
    "ax = axes[2, 1]\n",
    "ch_std = X.std(axis=(0, 2))\n",
    "bars = ax.barh(range(len(ch_names)), ch_std, color='steelblue')\n",
    "ax.axvline(100, color='r', linestyle='--', label='100 µV threshold')\n",
    "ax.set_yticks(range(len(ch_names)))\n",
    "ax.set_yticklabels(ch_names, fontsize=8)\n",
    "ax.set_xlabel('Std Amplitude (µV)')\n",
    "ax.set_title('Per-Channel Variability')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = r'c:\\Users\\yanni\\Desktop\\TUM MSEI\\2. Semester\\Lab\\Recording\\classification\\notebooks\\epoch_visualization.png'\n",
    "plt.savefig(save_path, dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Visualization saved to:\\n{save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "a6k6v77y8hs",
   "source": "# Participant Summary Table\nimport numpy as np\nimport pandas as pd\n\nprint(\"=\" * 70)\nprint(\"PARTICIPANT DATA QUALITY SUMMARY\")\nprint(\"=\" * 70)\n\n# Amplitude threshold for \"good\" trials (in µV)\nAMPLITUDE_THRESHOLD = 150\n\n# Collect data for all participants\nsummary_data = []\n\nfor sub_id, info in PARTICIPANT_INFO.items():\n    print(f\"\\nLoading {sub_id} ({info['name']})...\", end=\" \")\n    \n    try:\n        loader = RawEEGLoader()\n        eeg_path = DATA_DIR / sub_id / info['eeg_file']\n        data = loader.load(eeg_path=eeg_path, participant_id=sub_id)\n        \n        # Get crash info\n        crashes = info.get('crashes', [])\n        crash_trials = [c['repeated_eeg_trial'] for c in crashes] if crashes else []\n        \n        # Convert to µV and analyze\n        X_uv = data.X * 1e6\n        n_trials = X_uv.shape[0]\n        \n        # Per-trial max amplitude\n        trial_max = np.abs(X_uv).max(axis=(1, 2))\n        \n        # Good trials: max amplitude below threshold\n        good_trials = np.sum(trial_max < AMPLITUDE_THRESHOLD)\n        bad_trials = n_trials - good_trials\n        pct_good = (good_trials / n_trials) * 100\n        \n        # Bad trial indices (0-indexed)\n        bad_trial_indices = np.where(trial_max >= AMPLITUDE_THRESHOLD)[0].tolist()\n        \n        # Get amplitude stats\n        mean_max_amp = trial_max.mean()\n        max_max_amp = trial_max.max()\n        \n        summary_data.append({\n            'Participant': sub_id,\n            'Name': info['name'].capitalize(),\n            'Total Trials': n_trials,\n            'Crash Excluded': len(crash_trials),\n            'Good Trials': good_trials,\n            'Bad Trials': bad_trials,\n            '% Good': f\"{pct_good:.1f}%\",\n            'Mean Max (µV)': f\"{mean_max_amp:.0f}\",\n            'Max Max (µV)': f\"{max_max_amp:.0f}\",\n            'Bad Trial Indices': bad_trial_indices if len(bad_trial_indices) <= 10 else f\"{len(bad_trial_indices)} trials\"\n        })\n        \n        print(\"OK\")\n        \n    except Exception as e:\n        print(f\"FAILED: {e}\")\n        summary_data.append({\n            'Participant': sub_id,\n            'Name': info['name'].capitalize(),\n            'Total Trials': 'ERROR',\n            'Crash Excluded': len(info.get('crashes', [])),\n            'Good Trials': '-',\n            'Bad Trials': '-',\n            '% Good': '-',\n            'Mean Max (µV)': '-',\n            'Max Max (µV)': '-',\n            'Bad Trial Indices': str(e)[:30]\n        })\n\n# Create DataFrame and display\ndf = pd.DataFrame(summary_data)\n\nprint(\"\\n\" + \"=\" * 70)\nprint(f\"SUMMARY TABLE (threshold: ±{AMPLITUDE_THRESHOLD} µV)\")\nprint(\"=\" * 70)\n\n# Display main stats\ndisplay_cols = ['Participant', 'Name', 'Total Trials', 'Crash Excluded', \n                'Good Trials', 'Bad Trials', '% Good', 'Mean Max (µV)', 'Max Max (µV)']\nprint(df[display_cols].to_string(index=False))\n\n# Summary statistics\nprint(\"\\n\" + \"-\" * 70)\nvalid_rows = df[df['Total Trials'] != 'ERROR']\nif len(valid_rows) > 0:\n    total_trials = sum([r for r in valid_rows['Total Trials'] if isinstance(r, int)])\n    total_good = sum([r for r in valid_rows['Good Trials'] if isinstance(r, int)])\n    total_bad = sum([r for r in valid_rows['Bad Trials'] if isinstance(r, int)])\n    total_crash = sum([r for r in valid_rows['Crash Excluded'] if isinstance(r, int)])\n    \n    print(f\"TOTALS: {total_trials} trials across {len(valid_rows)} participants\")\n    print(f\"        {total_good} good trials ({total_good/total_trials*100:.1f}%)\")\n    print(f\"        {total_bad} trials with artifacts (>{AMPLITUDE_THRESHOLD} µV)\")\n    print(f\"        {total_crash} trials excluded due to crashes\")\n\n# Show bad trial indices per participant\nprint(\"\\n\" + \"=\" * 70)\nprint(\"BAD TRIAL INDICES (0-indexed, for exclusion)\")\nprint(\"=\" * 70)\nfor row in summary_data:\n    if isinstance(row['Bad Trial Indices'], list):\n        if len(row['Bad Trial Indices']) > 0:\n            print(f\"{row['Participant']}: {row['Bad Trial Indices']}\")\n        else:\n            print(f\"{row['Participant']}: None (all trials clean!)\")\n    else:\n        print(f\"{row['Participant']}: {row['Bad Trial Indices']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "wqtjs5mubel",
   "source": "### Test ICA Preprocessing",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "2msfw9ywysi",
   "source": "# Test ICA preprocessing on Sub03\n# Reload the module to pick up changes\nfor mod in list(sys.modules.keys()):\n    if 'raw_loader' in mod or 'data.loaders' in mod:\n        del sys.modules[mod]\nfrom data.loaders.raw_loader import RawEEGLoader\n\nprint(\"=\" * 70)\nprint(\"TEST: Loading Sub03 with ICA artifact removal\")\nprint(\"=\" * 70)\n\n# Configure loader with ICA enabled\nica_config = {\n    'apply_ica': True,\n    'ica_n_components': 15,          # Use 15 components (out of 30 channels)\n    'ica_method': 'fastica',\n    'ica_eog_threshold': 0.4,        # Correlation threshold for EOG detection\n    'ica_eog_channels': None,        # Auto-detect using frontal channels\n}\n\nloader_ica = RawEEGLoader(preprocessing_config=ica_config)\nprint(f\"\\nLoader config (ICA settings):\")\nprint(f\"  apply_ica: {loader_ica.config['apply_ica']}\")\nprint(f\"  ica_n_components: {loader_ica.config['ica_n_components']}\")\nprint(f\"  ica_method: {loader_ica.config['ica_method']}\")\nprint(f\"  ica_eog_threshold: {loader_ica.config['ica_eog_threshold']}\")\n\nprint(\"\\nLoading data with ICA (this may take a minute)...\")\ndata_ica = loader_ica.load(\n    eeg_path=DATA_DIR / \"Sub03\" / \"Simon.vhdr\",\n    participant_id=\"Sub03\"\n)\n\nprint(f\"\\nLoaded data:\")\nprint(f\"  Shape: {data_ica.X.shape}\")\nprint(f\"  n_trials: {data_ica.X.shape[0]}\")\n\n# Check ICA metadata\nif 'ica' in data_ica.metadata:\n    ica_info = data_ica.metadata['ica']\n    print(f\"\\nICA Info:\")\n    print(f\"  Detection method: {ica_info['detection_method']}\")\n    print(f\"  Components excluded: {ica_info['excluded_components']}\")\n    print(f\"  N components used: {ica_info['n_components']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "htu0w1n8udf",
   "source": "# Compare data quality: Before vs After ICA\nimport numpy as np\n\nprint(\"=\" * 70)\nprint(\"COMPARISON: Data Quality Before vs After ICA\")\nprint(\"=\" * 70)\n\n# Load without ICA for comparison (use the previously loaded data)\nX_before = data.X * 1e6  # From earlier cell (no ICA)\nX_after = data_ica.X * 1e6  # With ICA\n\nTHRESHOLD = 150  # µV\n\n# Calculate statistics\ndef compute_quality_stats(X, name):\n    trial_max = np.abs(X).max(axis=(1, 2))\n    good_trials = np.sum(trial_max < THRESHOLD)\n    pct_good = (good_trials / len(X)) * 100\n    \n    percentiles = np.percentile(X, [1, 99])\n    pct_within_range = np.mean(np.abs(X) < THRESHOLD) * 100\n    \n    return {\n        'name': name,\n        'n_trials': len(X),\n        'good_trials': good_trials,\n        'pct_good': pct_good,\n        'p1': percentiles[0],\n        'p99': percentiles[1],\n        'pct_within_range': pct_within_range,\n        'max_amplitude': np.abs(X).max(),\n        'mean_max_per_trial': trial_max.mean(),\n    }\n\nstats_before = compute_quality_stats(X_before, \"Without ICA\")\nstats_after = compute_quality_stats(X_after, \"With ICA\")\n\n# Print comparison table\nprint(f\"\\n{'Metric':<30} {'Without ICA':>15} {'With ICA':>15} {'Change':>12}\")\nprint(\"-\" * 72)\nprint(f\"{'Good trials (< 150µV)':<30} {stats_before['good_trials']:>15} {stats_after['good_trials']:>15} {stats_after['good_trials'] - stats_before['good_trials']:>+12}\")\nprint(f\"{'% Good trials':<30} {stats_before['pct_good']:>14.1f}% {stats_after['pct_good']:>14.1f}% {stats_after['pct_good'] - stats_before['pct_good']:>+11.1f}%\")\nprint(f\"{'% Data within ±150µV':<30} {stats_before['pct_within_range']:>14.1f}% {stats_after['pct_within_range']:>14.1f}% {stats_after['pct_within_range'] - stats_before['pct_within_range']:>+11.1f}%\")\nprint(f\"{'1st percentile (µV)':<30} {stats_before['p1']:>15.1f} {stats_after['p1']:>15.1f} {stats_after['p1'] - stats_before['p1']:>+12.1f}\")\nprint(f\"{'99th percentile (µV)':<30} {stats_before['p99']:>15.1f} {stats_after['p99']:>15.1f} {stats_after['p99'] - stats_before['p99']:>+12.1f}\")\nprint(f\"{'Max amplitude (µV)':<30} {stats_before['max_amplitude']:>15.1f} {stats_after['max_amplitude']:>15.1f} {stats_after['max_amplitude'] - stats_before['max_amplitude']:>+12.1f}\")\nprint(f\"{'Mean max per trial (µV)':<30} {stats_before['mean_max_per_trial']:>15.1f} {stats_after['mean_max_per_trial']:>15.1f} {stats_after['mean_max_per_trial'] - stats_before['mean_max_per_trial']:>+12.1f}\")\n\n# Summary\nprint(\"\\n\" + \"-\" * 72)\nimprovement = stats_after['pct_good'] - stats_before['pct_good']\nif improvement > 0:\n    print(f\"ICA improved data quality: {improvement:.1f}% more clean trials\")\nelif improvement < 0:\n    print(f\"ICA reduced clean trials by {-improvement:.1f}% (may need threshold adjustment)\")\nelse:\n    print(\"ICA had no effect on trial quality at this threshold\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_classifier_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}